# Are encrypted data distinguishable from random?

As with many complex topics that should have straightforward answers, it depends. **Let's find out!**

First, let's define what you mean by "random." There are three main kinds of random data of interest to us:

1. **True randomness** comes from natural sources. It is best to use when it's essential to have completely unpredictable
data, like for generating cryptographic keys. A good source for such data (short of digitizing the static from an analog 
radio) is https://www.random.org.
1. **Pseudo randomness** is generated by a mathematical algorithm, and is predictable. Since computers are by design 
deterministic, it is more difficult to make them unpredictable. Best to use when it doesn't matter if 
someone can "break" the randomness of your code, like for rolling dice in a game. Examples of such algorithms are the random 
module in Python and java.util.Random.
1. **Cryptographically secure randomness** is also generated by a mathematical algorithm, but one that specializes in complexity 
and relies on confusion and diffusion of data to mix it sufficiently well to measure as random. Wikipedia has an in-depth 
writeup of one such algorithm, the [Advanced Encryption Standard (AES)](https://en.wikipedia.org/wiki/Advanced_Encryption_Standard). Try to encrypt using AES by hand, I dare you. In Python, 
use the pycrypto library; for Java, use javax.crypto.Cipher.

The measure of randomness is entropy. But those in information science don't use the entropy measured in joules per kelvin,
like they do in thermodynamics. The important bit for our purposes is the greater the entropy, the greater the randomness.
For illustration, let's use an application known to reverse-engineers and pen-testers: [binwalk](https://github.com/ReFirmLabs/binwalk).

Following are figures generated by binwalk's entropy option (`binwalk -E file.hex`):

|Plaintext|Encrypted plaintext|
|--|--|
|![Plaintext file](https://github.com/xenloops/funwithcrypto/blob/master/images/montyplainentropy.png)|![Encrypted file](https://github.com/xenloops/funwithcrypto/blob/master/images/montycryptoentropy.png)|

Quite the difference! Note that the file with predictable data (e.g. most likely character is "e", "th" is common combination, etc.) has a fluctuating entropy across the file, but the encrypted file has a fairly consistent entropy of nearly 1.0 across the file.

Now let's compare the encryption entropy to that of different sources of randomness. The following are comparative entropies from:

|Natural randomness from [RANDOM.ORG](https://www.random.org/bytes/)|Pseudo randomness from Linux /dev/urandom|
|--|--|
|![Natural randomness](https://github.com/xenloops/funwithcrypto/blob/master/images/random.org.png)|![Pseudo randomness](https://github.com/xenloops/funwithcrypto/blob/master/images/linux.urandom.png)|

As you can see, there is no visual difference between the entropy measurements of encrypted or random data. While there are various rigorous methods of measuring randomness that involve scary mathematics, this is good enough to illustrate the point.

Please send questions, corrections, and/or snide remarks to xenloops at protonmail.

Note: The text file used was the full script of *Monty Python and the Holy Grail* as available from https://sacred-texts.com/neu/mphg/mphg.htm.

